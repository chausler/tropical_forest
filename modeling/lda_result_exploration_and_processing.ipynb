{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim import corpora, models, similarities\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tabulate import tabulate\n",
    "\n",
    "import dit\n",
    "from dit.divergences import jensen_shannon_divergence\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import pickle\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# path for models\n",
    "model_path = '/home/yyang/models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# path for corpora and dictionaries\n",
    "corp_path = '/home/yyang/corpora_and_dictionaries/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#load models and corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lda_10topics_names = ['lda_1506_10topics.model', 'lda_1507_10topics.model', 'lda_1508_10topics.model', \n",
    "                      'lda_1509_10topics.model', 'lda_1510_10topics.model', 'lda_1511_10topics.model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lda_15topics_names = ['lda_1506_15topics.model', 'lda_1507_15topics.model', 'lda_1508_15topics.model', \n",
    "                      'lda_1509_15topics.model', 'lda_1510_15topics.model', 'lda_1511_15topics.model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lda_25topics_names = ['lda_1506_25topics.model', 'lda_1507_25topics.model', 'lda_1508_25topics.model', \n",
    "                      'lda_1509_25topics.model', 'lda_1510_25topics.model', 'lda_1511_25topics.model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_lda_models(models, model_names):\n",
    "    for i in model_names:\n",
    "        models.append(gensim.models.ldamodel.LdaModel.load(model_path + i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "models = []\n",
    "load_lda_models(models, lda_10topics_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpora_names = ['corp_1506.mm', 'corp_1507.mm', 'corp_1508.mm', 'corp_1509.mm', 'corp_1510.mm', 'corp_1511.mm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corps = []\n",
    "for i in corpora_names:\n",
    "    corps.append(corpora.MmCorpus(corp_path + i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#lda result exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### show topics in models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_lda_topics(wordnum):\n",
    "    count = 0\n",
    "    for model in models:\n",
    "        alist = []\n",
    "        header = []\n",
    "        for i in range(len(model.show_topics(-1))):\n",
    "            alist.append([model.show_topic(i,wordnum)[j][1] for j in range(wordnum)])\n",
    "            header.append('topic {}'.format(i))\n",
    "        alist = np.asarray(alist)\n",
    "        print 'time slice {}'.format(count)\n",
    "        print tabulate(pd.DataFrame(alist.T), headers=header, tablefmt='psql') + '\\n'\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_lda_topics(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load topics from models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define how many words wanted in each topic\n",
    "topn_words = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topic_list = []\n",
    "for model in models:\n",
    "    alist = []\n",
    "    for i in range(len(model.show_topics(-1))):\n",
    "        sublist = []\n",
    "        sublist = dict(model.show_topic(i,topn_words))\n",
    "        sublist = dict(map(reversed, sublist.iteritems()))\n",
    "        alist.append(sublist)\n",
    "    topic_list.append(alist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### normalise words probabilities in topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for topics in topic_list:\n",
    "    for topic in topics:\n",
    "        total = float(sum(topic.values()))\n",
    "        for key in topic.keys():\n",
    "            topic[key] = topic[key] / total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### get words distribution in topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dists = []\n",
    "for topics in topic_list:\n",
    "    alist = []\n",
    "    for i in range(len(topics)):\n",
    "        alist.append(dit.ScalarDistribution(topics[i]))\n",
    "    dists.append(alist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate the divergence between topics in different month to get the similar topics crossing time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "similar_topics = []\n",
    "    \n",
    "count_a = 0\n",
    "count_b = 0\n",
    "for count_a in range(len(dists)):\n",
    "    a = dists[count_a]\n",
    "    for count_b in range(count_a+1, len(dists)):\n",
    "        b = dists[count_b]\n",
    "        newlist = []\n",
    "        index = []\n",
    "        index_count = 0\n",
    "        header = []         \n",
    "        for i in a:\n",
    "            sublist = []\n",
    "            for j in b:\n",
    "                div = jensen_shannon_divergence([i,j])\n",
    "                sublist.append(div) \n",
    "            if np.amin(sublist) < 0.5: # define divergence less than 0.5 as a same topic\n",
    "                similar_topics.append([count_a, index_count, count_b, sublist.index(np.amin(sublist))])\n",
    "            newlist.append(sublist)\n",
    "            index_count += 1\n",
    "            index.append('time_{0}_{1}'.format(count_a,index_count))\n",
    "            header.append('time_{0}_{1}'.format(count_b,index_count))\n",
    "        df = pd.DataFrame(newlist, index=index)\n",
    "#         print 'time slice {0} vs {1}'.format(count_a,count_b)\n",
    "#         print tabulate(df, headers=header, tablefmt='psql') + '\\n'\n",
    "    count_a += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###seperate divergence for similar topics in adjacent months and nonadjacent months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adjacent_topics = []\n",
    "\n",
    "for i in range(len(similar_topics)):\n",
    "    if similar_topics[i][0] == similar_topics[i][2]-1:\n",
    "        adjacent_topics.append(similar_topics[i])\n",
    "\n",
    "adjacent_topics = np.array(adjacent_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jumping_topics = []\n",
    "\n",
    "for i in range(len(similar_topics)):\n",
    "    if similar_topics[i][0:2] not in adjacent_topics[:,0:2].tolist():\n",
    "        count = 0\n",
    "        for j in range(len(jumping_topics)):\n",
    "            if similar_topics[i][0:2] == jumping_topics[j][0:2]:\n",
    "                count += 1\n",
    "        if count == 0:\n",
    "            jumping_topics.append(similar_topics[i])\n",
    "            \n",
    "jumping_topics = np.array(jumping_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###construct the topic vs time matrix to show topic changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columns = ['time slice {}'.format(i) for i in list(xrange(len(models)))]\n",
    "topic_time_matrix = pd.DataFrame(columns=columns)\n",
    "topic_time_matrix['common words'] = ''\n",
    "\n",
    "count = 0\n",
    "adict = defaultdict(list)\n",
    "\n",
    "for time in range(len(models)):\n",
    "    for topic in range(len(models[time].show_topics(-1))):\n",
    "        astring = '{0}{1}'.format(time,topic)\n",
    "#         for word in range(topn_words):\n",
    "#             astring += str(models[time].show_topic(topic,topn_words)[word][1]) + ' '\n",
    "            \n",
    "        if [time, topic] not in adjacent_topics[:,2:4].tolist() and [time, topic] not in jumping_topics[:,2:4].tolist():\n",
    "            topic_time_matrix.set_value('topic {}'.format(count), 'time slice {}'.format(time), str(astring))\n",
    "            topic_time_matrix.set_value('topic {}'.format(count), 'common words', \n",
    "                              set([models[time].show_topic(topic,topn_words)[i][1] for i in range(topn_words)]))\n",
    "            \n",
    "            adict['{0}{1}'.format(time,topic)].append(count)\n",
    "            count += 1\n",
    "            \n",
    "        else:\n",
    "            for i in range(len(jumping_topics)):\n",
    "                if (jumping_topics[i,2:4].tolist() == [time,topic]):\n",
    "                        topic_ids = adict.get('{0}{1}'.format(jumping_topics[i,0:2][0],jumping_topics[i,0:2][1]))\n",
    "                        for topic_id in topic_ids:\n",
    "                            topic_time_matrix['time slice {}'.format(time)]['topic {}'.format(topic_id)] = str(astring)\n",
    "                            topic_time_matrix['common words']['topic {}'.format(topic_id)] = \\\n",
    "                                topic_time_matrix['common words']['topic {}'.format(topic_id)]\\\n",
    "                                .intersection([models[time].show_topic(topic,topn_words)[i][1] \\\n",
    "                                               for i in range(topn_words)])\n",
    "                            adict['{0}{1}'.format(time,topic)].append(topic_id)\n",
    "                            \n",
    "            for i in range(len(adjacent_topics)):\n",
    "                if adjacent_topics[i,2:4].tolist() == [time, topic]:\n",
    "                    topic_ids = adict.get('{0}{1}'.format(adjacent_topics[i,0:2][0],adjacent_topics[i,0:2][1]))\n",
    "                    for topic_id in topic_ids:\n",
    "                        topic_time_matrix['time slice {}'.format(time)]['topic {}'.format(topic_id)] = str(astring)\n",
    "                        topic_time_matrix['common words']['topic {}'.format(topic_id)] = \\\n",
    "                            topic_time_matrix['common words']['topic {}'.format(topic_id)]\\\n",
    "                            .intersection([models[time].show_topic(topic,topn_words)[i][1] for i in range(topn_words)])\n",
    "                        adict['{0}{1}'.format(time,topic)].append(topic_id)\n",
    "\n",
    "topic_time_matrix = topic_time_matrix.replace(np.nan,' ', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###cluster merged topics together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in range(topic_time_matrix.shape[1]-1,-1,-1):\n",
    "    for i in range(topic_time_matrix.shape[0]):\n",
    "        for j in range(i+1,topic_time_matrix.shape[0]):\n",
    "            if topic_time_matrix.iloc[:,col][i] == topic_time_matrix.iloc[:,col][j] and \\\n",
    "               topic_time_matrix.iloc[:,col][j] != ' ':\n",
    "                    same = pd.DataFrame(columns=topic_time_matrix.columns.values.tolist())\n",
    "                    same.loc[0] = topic_time_matrix.iloc[j]\n",
    "                    topic_time_matrix.drop(topic_time_matrix.index[j], inplace=True)\n",
    "                    temp = topic_time_matrix.iloc[i+1:]\n",
    "                    topic_time_matrix.drop(topic_time_matrix.index[i+1:], inplace=True)\n",
    "                    topic_time_matrix = pd.concat([topic_time_matrix, same], ignore_index=True)\n",
    "                    topic_time_matrix = pd.concat([topic_time_matrix, temp], ignore_index=True)\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time slice 0</th>\n",
       "      <th>time slice 1</th>\n",
       "      <th>time slice 2</th>\n",
       "      <th>time slice 3</th>\n",
       "      <th>time slice 4</th>\n",
       "      <th>time slice 5</th>\n",
       "      <th>common words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00</td>\n",
       "      <td>15</td>\n",
       "      <td>26</td>\n",
       "      <td>37</td>\n",
       "      <td>48</td>\n",
       "      <td>58</td>\n",
       "      <td>{credit, account, please, thank, card}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>{status, timothy, process, remote, description...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02</td>\n",
       "      <td>13</td>\n",
       "      <td>21</td>\n",
       "      <td>36</td>\n",
       "      <td>45</td>\n",
       "      <td></td>\n",
       "      <td>{receive, please}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04</td>\n",
       "      <td>13</td>\n",
       "      <td>21</td>\n",
       "      <td>36</td>\n",
       "      <td>45</td>\n",
       "      <td></td>\n",
       "      <td>{information, use, intend, sender, confidentia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>03</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>30</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>{do, ser, favor, support, tier, eu, mail, tick...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>05</td>\n",
       "      <td>14</td>\n",
       "      <td>28</td>\n",
       "      <td>33</td>\n",
       "      <td>44</td>\n",
       "      <td>55</td>\n",
       "      <td>{right, thank, anything, get, else, go, see, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>16</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>40</td>\n",
       "      <td>55</td>\n",
       "      <td>{set, like, get, send, one, see, ticket}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>06</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "      <td>31</td>\n",
       "      <td>43</td>\n",
       "      <td>53</td>\n",
       "      <td>{customer, thank, get, support, advocate, plea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>09</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "      <td>31</td>\n",
       "      <td>43</td>\n",
       "      <td>53</td>\n",
       "      <td>{customer, thank, get, support, advocate, know...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td>11</td>\n",
       "      <td>22</td>\n",
       "      <td>31</td>\n",
       "      <td>43</td>\n",
       "      <td>53</td>\n",
       "      <td>{customer, thank, get, support, advocate, plea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>29</td>\n",
       "      <td>31</td>\n",
       "      <td>43</td>\n",
       "      <td>53</td>\n",
       "      <td>{customer, thank, get, support, advocate, plea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td></td>\n",
       "      <td>17</td>\n",
       "      <td></td>\n",
       "      <td>34</td>\n",
       "      <td></td>\n",
       "      <td>53</td>\n",
       "      <td>{customer, support, advocate, way, tier, ticket}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>24</td>\n",
       "      <td></td>\n",
       "      <td>49</td>\n",
       "      <td>53</td>\n",
       "      <td>{customer, see, support, get}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>07</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>{customer, cause, thank, issue, fix, work, jun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>08</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>{benjamin, pay, account, sheet, log, hub, info...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>25</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>{customer, thank, get, advocate, please, numbe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td></td>\n",
       "      <td>18</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>{part, account, hub, dell, process, list, inte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td></td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>35</td>\n",
       "      <td>47</td>\n",
       "      <td>57</td>\n",
       "      <td>{link, please, thank}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>23</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>{inbound, document, outbound, part, receive, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>27</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>{security, remote, name, service, receive, req...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>32</td>\n",
       "      <td></td>\n",
       "      <td>56</td>\n",
       "      <td>{code, record, receive, update, value, process...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>38</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>{benjamin, customer, par, ma, service, support...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>39</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>{customer, account, like, help, reseller, get,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>41</td>\n",
       "      <td></td>\n",
       "      <td>{customer, benjamin, use, like, star, help, bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>42</td>\n",
       "      <td></td>\n",
       "      <td>{code, associate, process, make, document, ple...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>46</td>\n",
       "      <td></td>\n",
       "      <td>{leave, enroll, pinto, width, text, caller, pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>50</td>\n",
       "      <td>{customer, information, account, work, intend,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>51</td>\n",
       "      <td>{hacker, web, product, help, ca, center, con, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>52</td>\n",
       "      <td>{customer, great, love, thank, service, simple...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>54</td>\n",
       "      <td>{satisfaction, van, thank, coupon, help, dan, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>59</td>\n",
       "      <td>{brown, mas, pinto, khan, do, die, support, ad...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   time slice 0 time slice 1 time slice 2 time slice 3 time slice 4  \\\n",
       "0            00           15           26           37           48   \n",
       "1            01                                                       \n",
       "2            02           13           21           36           45   \n",
       "3            04           13           21           36           45   \n",
       "4            03                                     30                \n",
       "5            05           14           28           33           44   \n",
       "6                         16                                     40   \n",
       "7            06           10           22           31           43   \n",
       "8            09           10           22           31           43   \n",
       "9                         11           22           31           43   \n",
       "10                                     29           31           43   \n",
       "11                        17                        34                \n",
       "12                                     24                        49   \n",
       "13           07                                                       \n",
       "14           08                                                       \n",
       "15                        12           25                             \n",
       "16                        18                                          \n",
       "17                        19           20           35           47   \n",
       "18                                     23                             \n",
       "19                                     27                             \n",
       "20                                                  32                \n",
       "21                                                  38                \n",
       "22                                                  39                \n",
       "23                                                               41   \n",
       "24                                                               42   \n",
       "25                                                               46   \n",
       "26                                                                    \n",
       "27                                                                    \n",
       "28                                                                    \n",
       "29                                                                    \n",
       "30                                                                    \n",
       "\n",
       "   time slice 5                                       common words  \n",
       "0            58             {credit, account, please, thank, card}  \n",
       "1                {status, timothy, process, remote, description...  \n",
       "2                                                {receive, please}  \n",
       "3                {information, use, intend, sender, confidentia...  \n",
       "4                {do, ser, favor, support, tier, eu, mail, tick...  \n",
       "5            55  {right, thank, anything, get, else, go, see, c...  \n",
       "6            55           {set, like, get, send, one, see, ticket}  \n",
       "7            53  {customer, thank, get, support, advocate, plea...  \n",
       "8            53  {customer, thank, get, support, advocate, know...  \n",
       "9            53  {customer, thank, get, support, advocate, plea...  \n",
       "10           53  {customer, thank, get, support, advocate, plea...  \n",
       "11           53   {customer, support, advocate, way, tier, ticket}  \n",
       "12           53                      {customer, see, support, get}  \n",
       "13               {customer, cause, thank, issue, fix, work, jun...  \n",
       "14               {benjamin, pay, account, sheet, log, hub, info...  \n",
       "15               {customer, thank, get, advocate, please, numbe...  \n",
       "16               {part, account, hub, dell, process, list, inte...  \n",
       "17           57                              {link, please, thank}  \n",
       "18               {inbound, document, outbound, part, receive, n...  \n",
       "19               {security, remote, name, service, receive, req...  \n",
       "20           56  {code, record, receive, update, value, process...  \n",
       "21               {benjamin, customer, par, ma, service, support...  \n",
       "22               {customer, account, like, help, reseller, get,...  \n",
       "23               {customer, benjamin, use, like, star, help, bu...  \n",
       "24               {code, associate, process, make, document, ple...  \n",
       "25               {leave, enroll, pinto, width, text, caller, pl...  \n",
       "26           50  {customer, information, account, work, intend,...  \n",
       "27           51  {hacker, web, product, help, ca, center, con, ...  \n",
       "28           52  {customer, great, love, thank, service, simple...  \n",
       "29           54  {satisfaction, van, thank, coupon, help, dan, ...  \n",
       "30           59  {brown, mas, pinto, khan, do, die, support, ad...  "
      ]
     },
     "execution_count": 490,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_time_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topic_time_matrix.to_pickle('/home/yyang/data/lda_topic_time_matrix_10.mm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#lda result processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##calculate topic popularity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###calculate topic distribution for documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_list = []\n",
    "\n",
    "for i in range(len(models)):\n",
    "    topics_list = []\n",
    "    dists = [models[i].get_document_topics(j) for j in corps[i]]\n",
    "    for j in range(len(dists)):\n",
    "        topics_dict = {}\n",
    "        for k in range(len(dists[j])):\n",
    "            if dists[j][k][1] > 0.1: #define probability threshold as 0.1\n",
    "                topics_dict[dists[j][k][0]] = 1\n",
    "        topics_list.append(topics_dict)\n",
    "    all_list.append(topics_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###aggregate topic distribution crossing documents to get topic popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topic_dicts = [dict(sum(map(Counter, i),Counter())) for i in all_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "for adict in topic_dicts:\n",
    "    for k in adict.keys():\n",
    "        adict['{0}{1}'.format(count,k)] = adict.pop(k)\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "popularity = {}\n",
    "for d in topic_dicts:\n",
    "    popularity.update(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'00': 5376,\n",
       " '01': 6729,\n",
       " '02': 9041,\n",
       " '03': 3214,\n",
       " '04': 7814,\n",
       " '05': 13399,\n",
       " '06': 14261,\n",
       " '07': 5561,\n",
       " '08': 3622,\n",
       " '09': 16096,\n",
       " '10': 16226,\n",
       " '11': 10167,\n",
       " '12': 11106,\n",
       " '13': 6745,\n",
       " '14': 10321,\n",
       " '15': 8038,\n",
       " '16': 6602,\n",
       " '17': 5427,\n",
       " '18': 1983,\n",
       " '19': 9049,\n",
       " '20': 10180,\n",
       " '21': 6271,\n",
       " '22': 15043,\n",
       " '23': 4333,\n",
       " '24': 8176,\n",
       " '25': 12300,\n",
       " '26': 5574,\n",
       " '27': 3808,\n",
       " '28': 7835,\n",
       " '29': 15063,\n",
       " '30': 4391,\n",
       " '31': 22365,\n",
       " '32': 3036,\n",
       " '33': 13136,\n",
       " '34': 12303,\n",
       " '35': 6362,\n",
       " '36': 7015,\n",
       " '37': 7952,\n",
       " '38': 2899,\n",
       " '39': 11452,\n",
       " '40': 15177,\n",
       " '41': 8287,\n",
       " '42': 2433,\n",
       " '43': 18504,\n",
       " '44': 11355,\n",
       " '45': 7507,\n",
       " '46': 7505,\n",
       " '47': 4256,\n",
       " '48': 9540,\n",
       " '49': 14785,\n",
       " '50': 9009,\n",
       " '51': 9476,\n",
       " '52': 9071,\n",
       " '53': 17461,\n",
       " '54': 5371,\n",
       " '55': 20685,\n",
       " '56': 4033,\n",
       " '57': 6390,\n",
       " '58': 9734,\n",
       " '59': 6681}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('/home/yyang/data/lda_topic_popularity_10.mm', 'wb') as f:\n",
    "    pickle.dump(popularity, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##construct json objects for visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###loda models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "models = []\n",
    "load_lda_models(models, lda_10topics_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###load topic vs time matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topic_time_matrix = pd.read_pickle('/home/yyang/data/lda_topic_time_matrix_10.mm') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topic_time_matrix.columns = [201506, 201507, 201508, 201509, 201510, 201511, 'words']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###load topic popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('/home/yyang/data/lda_topic_popularity_10.mm', 'rb') as f:\n",
    "    popularity = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###combine matrix and popularity to create json object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "array = []\n",
    "\n",
    "for i in range(topic_time_matrix.shape[0]):\n",
    "    data = []\n",
    "    new_row = []\n",
    "    count_same = 0\n",
    "    \n",
    "    for j in range(topic_time_matrix.shape[1]-1):\n",
    "        cell = []\n",
    "        new_cell = []\n",
    "        \n",
    "        if topic_time_matrix.iloc[i].iloc[j] != ' ':\n",
    "            cell.append(topic_time_matrix.columns[j])\n",
    "            cell.append(topic_time_matrix.iloc[i].iloc[j])\n",
    "            \n",
    "            for k in range(i) + range(i+1,topic_time_matrix.shape[0]):\n",
    "                if topic_time_matrix.iloc[:,j][i] == topic_time_matrix.iloc[:,j][k] and \\\n",
    "                   topic_time_matrix.iloc[:,j][k] != ' ':\n",
    "                        count_same += 1\n",
    "            \n",
    "            if count_same == 0:\n",
    "                cell.append(int(round(popularity[topic_time_matrix.iloc[i].iloc[j]])))\n",
    "            else:\n",
    "                cell.append(' ')\n",
    "                new_cell.append(topic_time_matrix.columns[j])\n",
    "                new_cell.append(topic_time_matrix.iloc[i].iloc[j])\n",
    "                new_cell.append(int(round(popularity[topic_time_matrix.iloc[i].iloc[j]])))\n",
    "                new_row.append(new_cell)  \n",
    " \n",
    "            data.append(cell)\n",
    "    array.append(data)\n",
    "    \n",
    "    if count_same != 0:\n",
    "        count_add = 0\n",
    "        for z in range(len(array)):\n",
    "            if new_row == array[z]:\n",
    "                count_add += 1\n",
    "        if count_add == 0:\n",
    "            array.append(new_row)\n",
    "\n",
    "for i in range(len(array)):\n",
    "    for j in range(i+1, len(array)):\n",
    "        for k in range(len(array[j])):\n",
    "            if array[j][k] in array[i] and array[j][k][2] != ' ':\n",
    "                if len(array[j]) > len(array[i]):\n",
    "                    for l in range(k,len(array[j])):\n",
    "                        array[j][l][2] = ' '\n",
    "                if len(array[i]) > len(array[j]):\n",
    "                    for l in range(len(array[i])):\n",
    "                        if array[i][l] == array[j][k]:\n",
    "                            array[i][l][2] = ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "complete_array = []\n",
    "\n",
    "for i in range(len(array)):\n",
    "    data = {}\n",
    "    common_words = {}\n",
    "    \n",
    "    for j in range(len(array[i])):\n",
    "        if array[i][j][2] != ' ':\n",
    "            topic = models[int(list(array[i][j][1])[0])].show_topic(int(array[i][j][1][1:]),20)\n",
    "            array[i][j].append(topic)\n",
    "        \n",
    "        words = [topic[k][1] for k in range(len(topic))]\n",
    "        if len(common_words) == 0:\n",
    "            common_words = set(words)\n",
    "        else:\n",
    "            common_words = set(common_words).intersection(words)\n",
    "        \n",
    "    data['topics'] = array[i]\n",
    "    data['words'] = ' '.join(common_words)\n",
    "    json_data = json.dumps(data)\n",
    "    complete_array.append(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('/home/yyang/data/lda_result_10.json', 'w') as f:\n",
    "     json.dump(complete_array, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
